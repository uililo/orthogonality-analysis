from utils import *
from joblib import dump, load 
import sys

from tqdm import tqdm

import numpy as np
import seaborn as sns
import umap.plot
import sklearn, re
import pandas as pd
from collections import Counter

ali = pd.read_csv('LibriSpeech/dev-clean.ali', delimiter=' ')
ali['spk_id'] = list(map(lambda x: re.match('([0-9]+)-*',x).group(1), ali.utt_id.values))
ali['utt_only'] = list(map(lambda x: re.search('-([0-9]+)-*',x).group(1), ali.utt_id.values))

ph_list = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH','IY','OW', 'OY', 'UH', 'UW', 'M', 'N', 'NG', 'R', 'L', 'Y', 'W', 'P', 'B', 'T', 'D', 'K', 'G', 'JH',  'HH', 'F', 'V', 'S', 'Z', 'DH', 'SH', 'CH', 'ZH', 'TH', 'SIL', 'SPN']
two_letter = ['AA', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH','IY','OW', 'OY', 'UH', 'UW', 'NG', 'SH', 'DH', 'SIL', 'EH', 'SPN', 'AY', 'AW', 'AE', 'CH' 'ZH' 'JH', 'TH', 'HH']
only_ph = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH','IY','OW', 'OY', 'UH', 'UW', 'M', 'N', 'NG', 'R', 'L', 'Y', 'W', 'P', 'B', 'T', 'D', 'K', 'G', 'JH',  'HH', 'F', 'V', 'S', 'Z', 'DH', 'SH', 'CH', 'ZH', 'TH']
consonants = [ 'M', 'N', 'NG', 'R', 'L', 'Y', 'W', 'P', 'B', 'T', 'D', 'K', 'G', 'JH',  'HH', 'F', 'V', 'S', 'Z', 'DH', 'SH', 'CH', 'ZH', 'TH']
vowels = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH','IY','OW', 'OY', 'UH', 'UW']
clean_spk = ['1272', '174', '2078', '2086', '2428', '251', '2803', '2902', '3000', '3170', '3752', '422', '5536', '5694', '6241', '6295', '652', '777', '8297', '7976', '1462', '1673', '1919', '1988', '1993', '2035', '2277', '2412', '3081', '3536', '3576', '3853', '5338', '5895', '6313', '6319', '6345', '7850', '84', '8842']
other_spk = ['116', '1255', '1585', '1630', '1650', '1651', '1686', '1701', '2506', '3660', '3663', '3915', '4153', '4323', '4515', '4570', '4572', '4831', '5543', '5849', '6123', '6267', '6455', '6467', '6599', '6841', '700', '7601', '7641', '7697', '8173', '8254', '8288']
train_spk = ['374','7800','2514','3240','1088','5456','5750','1246','8238','1263','7505','587','226','1743','4214','5789','7635','5390','307','7447','4362','6529','233','3242','1624','4297','6181','6367','3723','8123','6563','403','5778','3112','7312','7367','7078','32','5322','3214','6818','481','5104','6385','5192','8226','3830','2989','8324','163','150','6476','1069','3983','1183','4788','426','311','2196','103','446','1502','8975','8770','1992','5678','8014','2182','7178','201','1034','5703','1363','250','6836','3168','1553','5163','89','1334','19','5393','4481','4160','8312','6415','87','7067','5688','2843','909','40','322','8797','2764','6848','3947','4014','6531','3664','3259','4441','7794','5463','5049','4018','4088','4853','7226','4859','78','7113','3440','460','2893','4680','302','4830','2518','4898','7780','1926','1963','1841','3526','254','1970','6209','458','7148','831','6147','839','8425','200','1723','2416','6019','4813','1455','2391','2910','6000','7302','2817','445','8468','2384','8630','4267','26','118','328','1867','3374','5022','8108','6081','8095','5514','8838','2007','2002','196','248','198','4340','5339','6454','4051','3982','6078','3857','1098','5867','2159','83','730','1235','8629','696','289','1116','5808','8063','8465','6272','6064','412','3607','1594','7278','625','2836','7859','3807','1355','332','8580','911','6880','8051','8088','3436','887','3879','39','3235','211','5652','2136','4406','27','1737','7059','125','3486','2911','7190','6437','2092','7517','6925','8747','7402','8609','2691','2952','1040','1081','2289','298','4397','7264','1578','60','229','3699','8419','4137','405','2436','1898','7511','4195','669','5561','1447','441','8098','4640']


def find_spk_dims(direc,frame_rate=100):
    spk_vecs = []
    for spk in tqdm(clean_spk):
        # print(spk)
        x_features, x_phones = aggregate_feat_phone(spk, ali, direc,frame_rate=50)
        # x_vectors = compute_phone_centroid(x_features, x_phones)
        ph_id=np.array([i in only_ph for i in x_phones]).astype(bool)
        spk_vecs.append(np.mean(x_features,axis=0))
        # spk_vecs.append(np.mean(x_features[ph_id],axis=0))
    spk_vecs = np.array(spk_vecs)
    spk_vec_n = spk_vecs - np.mean(spk_vecs, axis=1)[:,None]
    pca_spk = PCA(n_components=len(set(ali.spk_id.values)))
    # print(spk_vec_n.shape)
    pca_spk.fit(spk_vec_n)
    return pca_spk

spk_pca = find_spk_dims(sys.argv[1])
dump(spk_pca,sys.argv[1]+'/'+sys.argv[2])

